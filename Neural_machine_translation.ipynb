{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZK3H5IhJaQF",
        "outputId": "ae47000b-9b58-43f3-c0d8-1c885256ae2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.4)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.7)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UDD-cROrJfMo"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_6yUmtTJjez",
        "outputId": "641861e0-c45f-4d4b-ab3a-1934e99e8827"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: aryan7004\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/devicharith/language-translation-englishfrench\n",
            "Downloading language-translation-englishfrench.zip to ./language-translation-englishfrench\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3.51M/3.51M [00:00<00:00, 5.65MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "od.download('https://www.kaggle.com/datasets/devicharith/language-translation-englishfrench')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fbZLvtpeJCgf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "f9ysscvNDgH2"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "e6SwWPpvSoha"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "D9Wh1ZqVKCOV"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/language-translation-englishfrench/eng_-french.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Uy3ENGN_KHcT",
        "outputId": "50ad6cbe-0d7d-48e2-b628-74d1d3b5ba70"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-aebee692-51e3-46f0-ac76-2c85ce112986\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English words/sentences</th>\n",
              "      <th>French words/sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Cours !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courez !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who?</td>\n",
              "      <td>Qui ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Ça alors !</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aebee692-51e3-46f0-ac76-2c85ce112986')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aebee692-51e3-46f0-ac76-2c85ce112986 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aebee692-51e3-46f0-ac76-2c85ce112986');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0586dd90-4c03-4bac-ae2b-3d0a9c48fd1b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0586dd90-4c03-4bac-ae2b-3d0a9c48fd1b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0586dd90-4c03-4bac-ae2b-3d0a9c48fd1b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  English words/sentences French words/sentences\n",
              "0                     Hi.                 Salut!\n",
              "1                    Run!                Cours !\n",
              "2                    Run!               Courez !\n",
              "3                    Who?                  Qui ?\n",
              "4                    Wow!             Ça alors !"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZJSnGIIKNv9",
        "outputId": "c8413b71-051b-4902-d126-74e348406ee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 175621 entries, 0 to 175620\n",
            "Data columns (total 2 columns):\n",
            " #   Column                   Non-Null Count   Dtype \n",
            "---  ------                   --------------   ----- \n",
            " 0   English words/sentences  175621 non-null  object\n",
            " 1   French words/sentences   175621 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 2.7+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qaBAMrJMBiid"
      },
      "outputs": [],
      "source": [
        "df['English words/sentences'].drop_duplicates(inplace = True)\n",
        "df['French words/sentences'].drop_duplicates(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxsxRZdpCsQi",
        "outputId": "dd46127a-919c-40d8-9b0d-a724740d221a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "123100"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['English words/sentences'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gewE70EgC0Gm",
        "outputId": "2665f362-c73b-4919-8bc0-25d7e9fb610b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "165975"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['French words/sentences'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ij3v7GSgDq1f"
      },
      "outputs": [],
      "source": [
        "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\", \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2O5YGp8jC9uM"
      },
      "outputs": [],
      "source": [
        "# text preprocessing\n",
        "def preprocess(text,language):\n",
        "  text = text.lower()\n",
        "  if language=='English':\n",
        "    text = ' '.join(contractions[word] if word in contractions else word for word in text.split())\n",
        "  text = re.sub(r\"[.'!#$%&\\'()*+,-./:;<=>?@[\\\\]^ `{|}~]\",\" \",text)\n",
        "  text = ' '.join([word for word in text.split()])\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Bo0KS5HlX3Uj"
      },
      "outputs": [],
      "source": [
        "df[\"English words/sentences\"] = df['English words/sentences'].apply(lambda x:preprocess(x,\"English\"))\n",
        "df[\"French words/sentences\"] = df['French words/sentences'].apply(lambda x:preprocess(x,\"French\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "STsWxcOEYcAz",
        "outputId": "093785d5-52b1-461c-ccd1-8c8d61b4b0c8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3277a8f6-ccf0-4319-ade0-413ff506c9aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English words/sentences</th>\n",
              "      <th>French words/sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi.</td>\n",
              "      <td>salut!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>run!</td>\n",
              "      <td>cours !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run!</td>\n",
              "      <td>courez !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>who?</td>\n",
              "      <td>qui ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wow!</td>\n",
              "      <td>ça alors !</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3277a8f6-ccf0-4319-ade0-413ff506c9aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3277a8f6-ccf0-4319-ade0-413ff506c9aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3277a8f6-ccf0-4319-ade0-413ff506c9aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a3bc951f-9190-4b47-9fa6-20ec8fc5fbb5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a3bc951f-9190-4b47-9fa6-20ec8fc5fbb5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a3bc951f-9190-4b47-9fa6-20ec8fc5fbb5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  English words/sentences French words/sentences\n",
              "0                     hi.                 salut!\n",
              "1                    run!                cours !\n",
              "2                    run!               courez !\n",
              "3                    who?                  qui ?\n",
              "4                    wow!             ça alors !"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8vtenWEuKP3Y"
      },
      "outputs": [],
      "source": [
        "sentence_en = df['English words/sentences'].to_numpy()\n",
        "sentence_fr = df['French words/sentences'].to_numpy()\n",
        "valid_fraction = 0.1\n",
        "valid_len = int(len(df)*valid_fraction)\n",
        "train_en = sentence_en[:-valid_len]\n",
        "train_fr = sentence_fr[:-valid_len]\n",
        "valid_en = sentence_en[-valid_len:]\n",
        "valid_fr = sentence_fr[-valid_len:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "aCirqtSgXTK-"
      },
      "outputs": [],
      "source": [
        "def prepare_input_and_target_dataset(sentence_en,sentence_fr):\n",
        "  return (sentence_en,b\"startofseq \"+sentence_fr),sentence_fr+b\" endofseq\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRL5dBGxW_wA"
      },
      "outputs": [],
      "source": [
        "def datasetfrom_sentence(sentence_en,\n",
        "                         sentence_fr,\n",
        "                         batch_size = 32,\n",
        "                         cache = True,\n",
        "                         shuffle = False,\n",
        "                         shuffle_buffer_size = 10_000,\n",
        "                         seed = None):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((sentence_en,sentence_fr))\n",
        "  dataset = dataset.map(prepare_input_and_target_dataset,num_parallel_calls = tf.data.AUTOTUNE)\n",
        "  if cache:\n",
        "    dataset = dataset.cache()\n",
        "  if shuffle:\n",
        "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
        "  return dataset.batch(batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KP3bPX24npr3"
      },
      "outputs": [],
      "source": [
        "train_ds = datasetfrom_sentence(train_en,train_fr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9MjpcJaS4pg",
        "outputId": "a03a61cb-05bc-408a-f366-2e64a018c605"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<_BatchDataset element_spec=((TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None,), dtype=tf.string, name=None))>\n"
          ]
        }
      ],
      "source": [
        "print(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibdPy5ZpzpUE"
      },
      "outputs": [],
      "source": [
        "valid_ds = datasetfrom_sentence(valid_en,valid_fr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gxu0OkwNz3iD",
        "outputId": "7ad17730-e228-428f-cd52-4d51bddeedab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((<tf.Tensor: shape=(32,), dtype=string, numpy=\n",
              "  array([b'hi.', b'run!', b'run!', b'who?', b'wow!', b'fire!', b'help!',\n",
              "         b'jump.', b'stop!', b'stop!', b'stop!', b'wait!', b'wait!',\n",
              "         b'go on.', b'go on.', b'go on.', b'hello!', b'hello!', b'i see.',\n",
              "         b'i try.', b'i won!', b'i won!', b'i won.', b'oh no!', b'attack!',\n",
              "         b'attack!', b'cheers!', b'cheers!', b'cheers!', b'cheers!',\n",
              "         b'get up.', b'go now.'], dtype=object)>,\n",
              "  <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
              "  array([b'startofseq salut!', b'startofseq cours !',\n",
              "         b'startofseq courez !', b'startofseq qui ?',\n",
              "         b'startofseq \\xc3\\xa7a alors !', b'startofseq au feu !',\n",
              "         b\"startofseq \\xc3\\xa0 l'aide !\", b'startofseq saute.',\n",
              "         b'startofseq \\xc3\\xa7a suffit !', b'startofseq stop !',\n",
              "         b'startofseq arr\\xc3\\xaate-toi !', b'startofseq attends !',\n",
              "         b'startofseq attendez !', b'startofseq poursuis.',\n",
              "         b'startofseq continuez.', b'startofseq poursuivez.',\n",
              "         b'startofseq bonjour !', b'startofseq salut !',\n",
              "         b'startofseq je comprends.', b\"startofseq j'essaye.\",\n",
              "         b\"startofseq j'ai gagn\\xc3\\xa9 !\",\n",
              "         b\"startofseq je l'ai emport\\xc3\\xa9 !\",\n",
              "         b'startofseq j\\xe2\\x80\\x99ai gagn\\xc3\\xa9.',\n",
              "         b'startofseq oh non !', b'startofseq attaque !',\n",
              "         b'startofseq attaquez !', b'startofseq sant\\xc3\\xa9 !',\n",
              "         b'startofseq \\xc3\\xa0 votre sant\\xc3\\xa9 !', b'startofseq merci !',\n",
              "         b'startofseq tchin-tchin !', b'startofseq l\\xc3\\xa8ve-toi.',\n",
              "         b'startofseq va, maintenant.'], dtype=object)>),\n",
              " <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
              " array([b'salut! endofseq', b'cours ! endofseq', b'courez ! endofseq',\n",
              "        b'qui ? endofseq', b'\\xc3\\xa7a alors ! endofseq',\n",
              "        b'au feu ! endofseq', b\"\\xc3\\xa0 l'aide ! endofseq\",\n",
              "        b'saute. endofseq', b'\\xc3\\xa7a suffit ! endofseq',\n",
              "        b'stop ! endofseq', b'arr\\xc3\\xaate-toi ! endofseq',\n",
              "        b'attends ! endofseq', b'attendez ! endofseq',\n",
              "        b'poursuis. endofseq', b'continuez. endofseq',\n",
              "        b'poursuivez. endofseq', b'bonjour ! endofseq',\n",
              "        b'salut ! endofseq', b'je comprends. endofseq',\n",
              "        b\"j'essaye. endofseq\", b\"j'ai gagn\\xc3\\xa9 ! endofseq\",\n",
              "        b\"je l'ai emport\\xc3\\xa9 ! endofseq\",\n",
              "        b'j\\xe2\\x80\\x99ai gagn\\xc3\\xa9. endofseq', b'oh non ! endofseq',\n",
              "        b'attaque ! endofseq', b'attaquez ! endofseq',\n",
              "        b'sant\\xc3\\xa9 ! endofseq',\n",
              "        b'\\xc3\\xa0 votre sant\\xc3\\xa9 ! endofseq', b'merci ! endofseq',\n",
              "        b'tchin-tchin ! endofseq', b'l\\xc3\\xa8ve-toi. endofseq',\n",
              "        b'va, maintenant. endofseq'], dtype=object)>)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(train_ds.take(1))[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4pukjgE61A2"
      },
      "outputs": [],
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Embedding,Dense,LSTM, Bidirectional, Attention,TextVectorization\n",
        "class BidirectionalEncoderandDecoderWithAttention(keras.Model):\n",
        "  def __init__(\n",
        "      self,\n",
        "      vocabulary_size = 5000,\n",
        "      max_length_size=50,\n",
        "      embedding_size = 256,\n",
        "      units_lstm =512,\n",
        "      **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.max_sentence_len = max_length_size\n",
        "    self.vocabulary_size = vocabulary_size\n",
        "\n",
        "    # tokenizer for english\n",
        "    self.tokenizer_en = TextVectorization(vocabulary_size,output_sequence_length = max_length_size)\n",
        "    self.tokenizer_fr = TextVectorization(vocabulary_size,output_sequence_length = max_length_size)\n",
        "    self.encoder_embeddings = Embedding(vocabulary_size,embedding_size,mask_zero = True)\n",
        "    self.encoder = Bidirectional(LSTM(units_lstm//2,return_sequences = True,return_state = True))\n",
        "    self.decoder_embeddings = Embedding(vocabulary_size,embedding_size,mask_zero = True)\n",
        "    self.decoder = LSTM(units_lstm,return_sequences = True)\n",
        "    self.attention = Attention()\n",
        "    self.output_layer = Dense(vocabulary_size,activation = 'softmax')\n",
        "  def call(self,inputs):\n",
        "      encoder_inputs,decoder_inputs = inputs\n",
        "\n",
        "      encoder_input_ids = self.tokenizer_en(encoder_inputs)\n",
        "\n",
        "      decoder_input_ids = self.tokenizer_fr(decoder_inputs)\n",
        "\n",
        "      encoder_embeddings = self.encoder_embeddings(encoder_input_ids)\n",
        "      decoder_embeddings = self.decoder_embeddings(decoder_input_ids)\n",
        "\n",
        "      encoder_op,*encoder_state = self.encoder(encoder_embeddings)\n",
        "      encoder_state = [\n",
        "            tf.concat(encoder_state[0::2], axis=-1),\n",
        "            tf.concat(encoder_state[1::2], axis=-1),\n",
        "        ]\n",
        "      decoder_op = self.decoder(decoder_embeddings,initial_state = encoder_state)\n",
        "      attention_output = self.attention([decoder_op,encoder_op])\n",
        "      output = self.output_layer(attention_output)\n",
        "      return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlndKq6h2cFB"
      },
      "outputs": [],
      "source": [
        "def adapts_compile_fit(model,\n",
        "                       train_data,\n",
        "                       valid_data,\n",
        "                       n_epochs = 40,\n",
        "                       n_patience = 20,\n",
        "                       init_lr = 0.001,\n",
        "                       lr_decay_rate = 0.1):\n",
        "  model.tokenizer_en.adapt(train_data.map(lambda sentence,target:sentence[0],num_parallel_calls = tf.data.AUTOTUNE,))\n",
        "  model.tokenizer_fr.adapt(train_data.map(lambda sentence,target:sentence[1]+b\" endofseq\",num_parallel_calls = tf.data.AUTOTUNE))\n",
        "\n",
        "  train_data_prepared = train_data.map(\n",
        "        lambda sentences, target: (sentences,model.tokenizer_fr(target)),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  valid_data_prepared = valid_data.map(\n",
        "        lambda sentences, target: (sentences,model.tokenizer_fr(target)),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience = n_patience,restore_best_weights = True)\n",
        "  n_decay_steps = n_epochs * len(list(train_data_prepared))\n",
        "  scheduled_lr = keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate=init_lr,\n",
        "        decay_steps=n_decay_steps,\n",
        "        decay_rate=lr_decay_rate)\n",
        "  model.compile(loss='sparse_categorical_crossentropy',\n",
        "                optimizer = keras.optimizers.RMSprop(learning_rate = scheduled_lr),\n",
        "                metrics = ['accuracy'])\n",
        "  return model.fit(train_data_prepared,\n",
        "                   epochs = n_epochs,\n",
        "                   validation_data = valid_data_prepared,\n",
        "                   callbacks = [early_stopping]\n",
        "                   ,verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRkkDHrmRF8H"
      },
      "outputs": [],
      "source": [
        "def prepare_input_and_target_dataset(sentence_en,sentence_fr):\n",
        "  return (sentence_en,b\"startofseq \"+sentence_fr),sentence_fr+b\" endofseq\"\n",
        "\n",
        "def datasetfrom_sentence(sentence_en,\n",
        "                         sentence_fr,\n",
        "                         batch_size = 32,\n",
        "                         cache = True,\n",
        "                         shuffle = False,\n",
        "                         shuffle_buffer_size = 10_000,\n",
        "                         seed = None):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((sentence_en,sentence_fr))\n",
        "  dataset = dataset.map(prepare_input_and_target_dataset,num_parallel_calls = tf.data.AUTOTUNE)\n",
        "  if cache:\n",
        "    dataset = dataset.cache()\n",
        "  if shuffle:\n",
        "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
        "  return dataset.batch(batch_size)\n",
        "\n",
        "def adapts_compile_fit(model,\n",
        "                       train_data,\n",
        "                       valid_data,\n",
        "                       n_epochs = 40,\n",
        "                       n_patience = 20,\n",
        "                       init_lr = 0.001,\n",
        "                       lr_decay_rate = 0.1):\n",
        "  model.tokenizer_en.adapt(train_data.map(lambda sentence,target:sentence[0],num_parallel_calls = tf.data.AUTOTUNE,))\n",
        "  model.tokenizer_fr.adapt(train_data.map(lambda sentence,target:sentence[1]+b\" endofseq\",num_parallel_calls = tf.data.AUTOTUNE))\n",
        "\n",
        "  train_data_prepared = train_data.map(\n",
        "        lambda sentences, target: (sentences,model.tokenizer_fr(target)),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  valid_data_prepared = valid_data.map(\n",
        "        lambda sentences, target: (sentences,model.tokenizer_fr(target)),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience = n_patience,restore_best_weights = True)\n",
        "  n_decay_steps = n_epochs * len(list(train_data_prepared))\n",
        "  scheduled_lr = keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate=init_lr,\n",
        "        decay_steps=n_decay_steps,\n",
        "        decay_rate=lr_decay_rate)\n",
        "  model.compile(loss='sparse_categorical_crossentropy',\n",
        "                optimizer = keras.optimizers.RMSprop(learning_rate = scheduled_lr),\n",
        "                metrics = ['accuracy'])\n",
        "  return model.fit(train_data_prepared,\n",
        "                   epochs = n_epochs,\n",
        "                   validation_data = valid_data_prepared,\n",
        "                   callbacks = [early_stopping]\n",
        "                   ,verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KccZv2m6Dvm9"
      },
      "outputs": [],
      "source": [
        "model = BidirectionalEncoderandDecoderWithAttention(max_length_size=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul4db9lHGQNa",
        "outputId": "08b72271-4893-424b-8bd5-359d9d406936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "4940/4940 [==============================] - 144s 26ms/step - loss: 2.9255 - accuracy: 0.4801 - val_loss: 2.7329 - val_accuracy: 0.4586\n",
            "Epoch 2/40\n",
            "4940/4940 [==============================] - 103s 21ms/step - loss: 1.9362 - accuracy: 0.5931 - val_loss: 2.5315 - val_accuracy: 0.4867\n",
            "Epoch 3/40\n",
            "4940/4940 [==============================] - 103s 21ms/step - loss: 1.6596 - accuracy: 0.6340 - val_loss: 2.4653 - val_accuracy: 0.5006\n",
            "Epoch 4/40\n",
            "4940/4940 [==============================] - 104s 21ms/step - loss: 1.4915 - accuracy: 0.6604 - val_loss: 2.4133 - val_accuracy: 0.5129\n",
            "Epoch 5/40\n",
            "4940/4940 [==============================] - 104s 21ms/step - loss: 1.3552 - accuracy: 0.6822 - val_loss: 2.4107 - val_accuracy: 0.5185\n",
            "Epoch 6/40\n",
            "4940/4940 [==============================] - 112s 23ms/step - loss: 1.2375 - accuracy: 0.7019 - val_loss: 2.4100 - val_accuracy: 0.5203\n",
            "Epoch 7/40\n",
            "4940/4940 [==============================] - 111s 22ms/step - loss: 1.1278 - accuracy: 0.7211 - val_loss: 2.4406 - val_accuracy: 0.5213\n",
            "Epoch 8/40\n",
            "4940/4940 [==============================] - 111s 23ms/step - loss: 1.0286 - accuracy: 0.7394 - val_loss: 2.4690 - val_accuracy: 0.5228\n",
            "Epoch 9/40\n",
            "4940/4940 [==============================] - 104s 21ms/step - loss: 0.9357 - accuracy: 0.7568 - val_loss: 2.5132 - val_accuracy: 0.5219\n",
            "Epoch 10/40\n",
            "4940/4940 [==============================] - 110s 22ms/step - loss: 0.8503 - accuracy: 0.7739 - val_loss: 2.5624 - val_accuracy: 0.5227\n",
            "Epoch 11/40\n",
            "4940/4940 [==============================] - 107s 22ms/step - loss: 0.7707 - accuracy: 0.7909 - val_loss: 2.6364 - val_accuracy: 0.5213\n",
            "Epoch 12/40\n",
            "4940/4940 [==============================] - 109s 22ms/step - loss: 0.6997 - accuracy: 0.8064 - val_loss: 2.7038 - val_accuracy: 0.5174\n",
            "Epoch 13/40\n",
            "4940/4940 [==============================] - 114s 23ms/step - loss: 0.6350 - accuracy: 0.8217 - val_loss: 2.7554 - val_accuracy: 0.5167\n",
            "Epoch 14/40\n",
            "4940/4940 [==============================] - 103s 21ms/step - loss: 0.5768 - accuracy: 0.8359 - val_loss: 2.8319 - val_accuracy: 0.5141\n",
            "Epoch 15/40\n",
            "4940/4940 [==============================] - 103s 21ms/step - loss: 0.5261 - accuracy: 0.8491 - val_loss: 2.8977 - val_accuracy: 0.5123\n",
            "Epoch 16/40\n",
            "4940/4940 [==============================] - 102s 21ms/step - loss: 0.4828 - accuracy: 0.8604 - val_loss: 2.9674 - val_accuracy: 0.5114\n",
            "Epoch 17/40\n",
            "4940/4940 [==============================] - 107s 22ms/step - loss: 0.4445 - accuracy: 0.8706 - val_loss: 3.0258 - val_accuracy: 0.5090\n",
            "Epoch 18/40\n",
            "4940/4940 [==============================] - 107s 22ms/step - loss: 0.4115 - accuracy: 0.8799 - val_loss: 3.1024 - val_accuracy: 0.5057\n"
          ]
        }
      ],
      "source": [
        "history = adapts_compile_fit(model,train_ds,valid_ds,init_lr = 0.01,lr_decay_rate=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fxnQpIRFKMK"
      },
      "outputs": [],
      "source": [
        "def translate(model,sentence_en):\n",
        "  answer = \"\"\n",
        "  for i in range(model.max_sentence_len):\n",
        "    X_encoded = np.array([sentence_en])\n",
        "    X_decoded = np.array([\"startofseq \"+answer])\n",
        "    y_prob = model.predict((X_encoded,X_decoded),verbose=0)[0,i]\n",
        "    y_prob_id = np.argmax(y_prob)\n",
        "    predicted_word = model.tokenizer_fr.get_vocabulary()[y_prob_id]\n",
        "    if predicted_word==\" endofseq\":\n",
        "      break\n",
        "    answer = answer + \" \" + predicted_word\n",
        "  return answer.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0a4HyFcPOg5"
      },
      "outputs": [],
      "source": [
        "translate_1 = translate(model,\"wow how?\")\n",
        "print(translate_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fy6Agmb7KG4"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(layers.Layer):\n",
        "\n",
        "  def __init__(\n",
        "      self,max_sentence_len = 50,embedding_size = 256, dtype = tf.float32, **kwargs\n",
        "      ):\n",
        "    super().__init__(dtype = dtype,**kwargs)\n",
        "    if embedding_size %2!=0:\n",
        "      raise ValueError(\"embedding_size must be even\")\n",
        "    p,i = np.meshgrid(np.arange(max_sentence_len),np.arange(embedding_size//2))\n",
        "    pos_emb = np.empty((1,max_sentence_len,embedding_size))\n",
        "    pos_emb[:,:,0::2] = np.sin(p/10_000**(2*i/embedding_size)).T\n",
        "    pos_emb[:,:,1::2] = np.cos(p/10_000**(2*i/embedding_size)).T\n",
        "    self.positional_embedding = tf.constant(pos_emb.astype(self.dtype))\n",
        "    self.supports_masking = True\n",
        "\n",
        "  def call(self, inputs):\n",
        "    batch_max_length = tf.shape(inputs)[1]\n",
        "    return inputs + self.positional_embedding[:, :batch_max_length]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJwmnLe7V0N-"
      },
      "outputs": [],
      "source": [
        "class Encoder(layers.Layer):\n",
        "\n",
        "  def __init__(\n",
        "      self,embedding_size = 256, n_attention_heads = 8,n_units_dense = 256, dropout_rate = 0.2,**kwargs\n",
        "      ):\n",
        "    super().__init__(**kwargs)\n",
        "    self.multi_head_attention = layers.MultiHeadAttention(n_attention_heads, embedding_size, dropout = dropout_rate)\n",
        "    self.feed_forward = keras.Sequential(\n",
        "        [\n",
        "            layers.Dense(n_units_dense, activation = \"relu\", kernel_initializer = \"he_normal\"),\n",
        "            layers.Dense(embedding_size, kernel_initializer= \"he_normal\")\n",
        "        ]\n",
        "    )\n",
        "    self.add = layers.Add()\n",
        "    self.normalization = layers.LayerNormalization()\n",
        "\n",
        "  def call(self,inputs,mask=None):\n",
        "      Z= inputs\n",
        "      skip_z = Z\n",
        "      Z = self.multi_head_attention(Z,value = Z,attention_mask = mask)\n",
        "      Z = self.normalization(self.add([Z,skip_z]))\n",
        "      skip_z = Z\n",
        "\n",
        "      Z = self.feed_forward(Z)\n",
        "      Z = self.normalization(self.add([Z,skip_z]))\n",
        "      return Z\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeC2cMI_YwAL"
      },
      "outputs": [],
      "source": [
        "class Decoder(layers.Layer):\n",
        "\n",
        "  def __init__(\n",
        "      self,embedding_size = 256,n_attention_head = 8,n_units_dense = 256,dropout_rate = 0.2,**kwargs\n",
        "      ):\n",
        "    super().__init__(**kwargs)\n",
        "    self.masked_multi_head_attention = layers.MultiHeadAttention(n_attention_head,embedding_size,dropout = dropout_rate)\n",
        "    self.multi_head_attention = layers.MultiHeadAttention(n_attention_head, embedding_size, dropout = dropout_rate)\n",
        "    self.normalization = layers.Normalization()\n",
        "    self.add = layers.Add()\n",
        "    self.feed_forward = keras.Sequential(\n",
        "        [\n",
        "            layers.Dense(n_units_dense,activation = \"relu\",kernel_initializer = \"he_normal\"),\n",
        "            layers.Dense(embedding_size,kernel_initializer = \"he_normal\"),\n",
        "            layers.Dropout(dropout_rate),\n",
        "        ]\n",
        "        )\n",
        "  def call(self,inputs,mask=None):\n",
        "    decoder_mask, encoder_mask = mask\n",
        "    Z, encoder_output = inputs\n",
        "    Z_skip = Z\n",
        "    Z = self.masked_multi_head_attention(Z,value=Z,attention_mask = decoder_mask)\n",
        "    Z = self.normalization(self.add([Z_skip,Z]))\n",
        "    Z_skip = Z\n",
        "    Z = self.multi_head_attention(Z,value = encoder_output,attention_mask = encoder_mask)\n",
        "    Z = self.normalization(self.add([Z,Z_skip]))\n",
        "    Z_skip = Z\n",
        "    Z = self.feed_forward(Z)\n",
        "    Z = self.normalization(self.add([Z_skip,Z]))\n",
        "    return Z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95I0JCPs_-lP"
      },
      "outputs": [],
      "source": [
        "class Transformer(keras.Model):\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      vocabulary_size = 5000,\n",
        "      max_sentence_len = 50,\n",
        "      embedding_size = 256,\n",
        "      n_encoder_decoder_blocks = 1,\n",
        "      n_attention_heads = 8,\n",
        "      n_units_dense = 256,\n",
        "      dropout_rate = 0.2,\n",
        "      **kwargs\n",
        "  ):\n",
        "   super().__init__(**kwargs)\n",
        "   self.max_sentence_len = max_sentence_len\n",
        "   self.tokenizer_en = layers.TextVectorization(\n",
        "      vocabulary_size, output_sequence_length = max_sentence_len\n",
        "   )\n",
        "   self.tokenizer_fr = layers.TextVectorization(\n",
        "      vocabulary_size, output_sequence_length = max_sentence_len\n",
        "   )\n",
        "   self.encoder_embedding = layers.Embedding(\n",
        "      vocabulary_size,embedding_size, mask_zero = True\n",
        "   )\n",
        "   self.decoder_embedding = layers.Embedding(\n",
        "      vocabulary_size, embedding_size, mask_zero = True\n",
        "   )\n",
        "   self.positional_encoding = PositionalEncoding(max_sentence_len,embedding_size)\n",
        "   self.encoder_blocks = [\n",
        "      Encoder(embedding_size,n_attention_heads,n_units_dense,dropout_rate)\n",
        "      for _ in range(n_encoder_decoder_blocks)\n",
        "   ]\n",
        "   self.decoder_blocks = [\n",
        "      Decoder(embedding_size,n_attention_heads,n_units_dense,dropout_rate)\n",
        "      for _ in range(n_encoder_decoder_blocks)\n",
        "   ]\n",
        "   self.output_layer = layers.Dense(vocabulary_size,activation = 'softmax')\n",
        "\n",
        "  def call(self,inputs):\n",
        "   encoder_inputs, decoder_inputs = inputs\n",
        "\n",
        "   encoder_input_ids = self.tokenizer_en(encoder_inputs)\n",
        "   decoder_input_ids = self.tokenizer_fr(decoder_inputs)\n",
        "\n",
        "   encoder_embeddings = self.encoder_embedding(encoder_input_ids)\n",
        "   decoder_embeddings = self.decoder_embedding(decoder_input_ids)\n",
        "\n",
        "   encoder_pos_embeddings = self.positional_encoding(encoder_embeddings)\n",
        "   decoder_pos_embeddings = self.positional_encoding(decoder_embeddings)\n",
        "\n",
        "   encoder_pad_mask = tf.math.not_equal(encoder_input_ids,0)[:,tf.newaxis]\n",
        "   decoder_pad_mask = tf.math.not_equal(decoder_input_ids,0)[:,tf.newaxis]\n",
        "   batch_max_len_decoder = tf.shape(decoder_embeddings)[1]\n",
        "   decoder_casual_mask = tf.linalg.band_part(tf.ones((batch_max_len_decoder, batch_max_len_decoder),tf.bool),-1,0)\n",
        "\n",
        "   decoder_mask = decoder_casual_mask & decoder_pad_mask\n",
        "\n",
        "   Z = encoder_pos_embeddings\n",
        "   for encoder_block in self.encoder_blocks:\n",
        "     Z = encoder_block(Z,mask = encoder_pad_mask)\n",
        "   encoder_output = Z\n",
        "   Z = decoder_pos_embeddings\n",
        "   for decoder_block in self.decoder_blocks:\n",
        "     Z = decoder_block(\n",
        "        [Z, encoder_output], mask = [decoder_mask, encoder_pad_mask]\n",
        "    )\n",
        "   Z = self.output_layer(Z)\n",
        "   return Z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPrSvEGYMz4v"
      },
      "outputs": [],
      "source": [
        "transformer_model = Transformer(max_sentence_len=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoZK0PFz4cpl",
        "outputId": "32780217-5fb3-4f6b-b7f4-e62a8f870751"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "4940/4940 [==============================] - 143s 27ms/step - loss: 2.4278 - accuracy: 0.6553 - val_loss: 3.9308 - val_accuracy: 0.3368\n",
            "Epoch 2/100\n",
            "4940/4940 [==============================] - 117s 24ms/step - loss: 1.8647 - accuracy: 0.6777 - val_loss: 3.9609 - val_accuracy: 0.3362\n",
            "Epoch 3/100\n",
            "4940/4940 [==============================] - 117s 24ms/step - loss: 1.8389 - accuracy: 0.6794 - val_loss: 3.7836 - val_accuracy: 0.3431\n",
            "Epoch 4/100\n",
            "4940/4940 [==============================] - 118s 24ms/step - loss: 1.8217 - accuracy: 0.6804 - val_loss: 3.7841 - val_accuracy: 0.3407\n",
            "Epoch 5/100\n",
            "4940/4940 [==============================] - 118s 24ms/step - loss: 1.8118 - accuracy: 0.6811 - val_loss: 3.7925 - val_accuracy: 0.3440\n",
            "Epoch 6/100\n",
            "4940/4940 [==============================] - 113s 23ms/step - loss: 1.8064 - accuracy: 0.6813 - val_loss: 3.7753 - val_accuracy: 0.3483\n",
            "Epoch 7/100\n",
            " 737/4940 [===>..........................] - ETA: 1:31 - loss: 1.1199 - accuracy: 0.8075"
          ]
        }
      ],
      "source": [
        "history_2 = adapts_compile_fit(transformer_model,train_ds,valid_ds,n_epochs=100,init_lr = 0.003,lr_decay_rate=0.04)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "W8htvdj-ydmK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import time\n",
        "import spacy\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torchtext\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "import multiprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZHfsoahMlFv5"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTnUMohRMx1E",
        "outputId": "e9b6b5b2-0c95-4bcd-fb48-5401b592cdb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'fr' are deprecated. Please use the\n",
            "full pipeline package name 'fr_core_news_sm' instead.\u001b[0m\n",
            "Collecting fr-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from fr-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download fr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "fhjDKQmIMydy"
      },
      "outputs": [],
      "source": [
        "en_tokenizer = spacy.load(\"en_core_web_sm\")\n",
        "fr_tokenizer = spacy.load(\"fr_core_news_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "E2ggiBL8gl3Y"
      },
      "outputs": [],
      "source": [
        "def data_process(sentence_en,sentence_fr):\n",
        "  data = []\n",
        "  for (en_sen,fr_sen) in zip(sentence_en,sentence_fr):\n",
        "    data.append((en_sen,fr_sen))\n",
        "  return data\n",
        "def generate_batch(data_batch):\n",
        "  en_batch,fr_batch = [],[]\n",
        "  for (en_item,fr_item) in data_batch:\n",
        "    en_batch.append(['<bos>'+en_item + '<eos>'])\n",
        "    fr_batch.append(['<bos>'+fr_item + '<eos>'])\n",
        "  return en_batch,fr_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "gLW2-NXWjMvB"
      },
      "outputs": [],
      "source": [
        "train_data = data_process(train_en,train_fr)\n",
        "valid_data = data_process(valid_en,valid_fr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "XVWI-CcmjNSb"
      },
      "outputs": [],
      "source": [
        "train_iter = DataLoader(train_data, batch_size=32,\n",
        "                        shuffle=True, collate_fn=generate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Z5RklTtPnxY9"
      },
      "outputs": [],
      "source": [
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "def yield_tokens_en(data_iter):\n",
        "    for (en_batch, fr_batch) in data_iter:\n",
        "        for en_sent in en_batch:\n",
        "            my_string = ' '.join(en_sent)\n",
        "            en_tokens = my_string.split()  # Split English sentence into tokens\n",
        "            yield en_tokens\n",
        "\n",
        "def yield_tokens_fr(data_iter):\n",
        "    for (en_batch, fr_batch) in data_iter:\n",
        "        for fr_sent in fr_batch:\n",
        "            my_string = ' '.join(fr_sent)\n",
        "            fr_tokens = my_string.split()  # Split English sentence into tokens\n",
        "            yield fr_tokens\n",
        "en_vocab = build_vocab_from_iterator(yield_tokens_en(train_iter),\n",
        "                                  min_freq=1,\n",
        "                                  specials=special_symbols,\n",
        "                                  special_first=True)\n",
        "fr_vocab = build_vocab_from_iterator(yield_tokens_fr(train_iter),\n",
        "                                  min_freq=1,\n",
        "                                  specials=special_symbols,\n",
        "                                  special_first=True)\n",
        "en_vocab.set_default_index(en_vocab['<unk>'])\n",
        "fr_vocab.set_default_index(fr_vocab['<unk>'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "i1R2cxL98jIV"
      },
      "outputs": [],
      "source": [
        "def collate_fn(data_batch):\n",
        "  en_batch = []\n",
        "  fr_batch = []\n",
        "  for (en_item,fr_item) in data_batch:\n",
        "    en_ids = torch.tensor([en_vocab[token] for token in en_item],dtype = torch.long)\n",
        "    fr_ids = torch.tensor([fr_vocab[token] for token in fr_item],dtype = torch.long)\n",
        "    # print(type(en_ids))\n",
        "    en_batch.append(torch.cat([torch.tensor([en_vocab['<bos>']]), en_ids ,torch.tensor([en_vocab['<eos>']])], dim=0))\n",
        "    fr_batch.append(torch.cat([torch.tensor([fr_vocab['<bos>']]), fr_ids ,torch.tensor([fr_vocab['<eos>']])], dim=0))\n",
        "    # print(type(e_tensor))\n",
        "  en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
        "  fr_batch = pad_sequence(fr_batch, padding_value=PAD_IDX)\n",
        "  return en_batch,fr_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ZpD3Y5vf-hJq"
      },
      "outputs": [],
      "source": [
        "train_data_token_iter = DataLoader(train_data, batch_size=32,\n",
        "                        shuffle=True, collate_fn=collate_fn)\n",
        "valid_data_token_iter = DataLoader(valid_data, batch_size=32,\n",
        "                        shuffle=True, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "wYPbt_lJDDvB"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size=512,\n",
        "                 maxlen = 50):\n",
        "        super(PositionalEmbedding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding):\n",
        "        return token_embedding + self.pos_embedding[:token_embedding.size(0), :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "rS0bW5KAm7BY"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self,embed_dim=512,n_heads = 8):\n",
        "    super(MultiHeadAttention,self).__init__()\n",
        "    self.embed_dim = embed_dim\n",
        "    self.n_heads = n_heads\n",
        "    self.single_head_dim = int(self.embed_dim/self.n_heads)\n",
        "\n",
        "    self.query_matrix = nn.Linear(self.single_head_dim,self.single_head_dim,bias = False)\n",
        "    self.key_matrix = nn.Linear(self.single_head_dim,self.single_head_dim,bias = False)\n",
        "    self.value_matrix = nn.Linear(self.single_head_dim,self.single_head_dim,bias = False)\n",
        "    self.output = nn.Linear(self.single_head_dim*self.n_heads,self.embed_dim)\n",
        "\n",
        "  def forward(self,key,query,value,mask=None):\n",
        "    batch_size = key.size(0)\n",
        "    seq_length = key.size(1)\n",
        "    seq_query_len = query.size(1)\n",
        "    key = key.view(batch_size,seq_length,self.n_heads,self.single_head_dim)\n",
        "    query = query.view(batch_size,seq_query_len,self.n_heads,self.single_head_dim)\n",
        "    value = value.view(batch_size,seq_length,self.n_heads,self.single_head_dim)\n",
        "\n",
        "    k = self.key_matrix(key)\n",
        "    q = self.query_matrix(query)\n",
        "    v = self.value_matrix(value)\n",
        "\n",
        "    k = k.transpose(1,2)\n",
        "    q = q.transpose(1,2)\n",
        "    v = v.transpose(1,2)\n",
        "\n",
        "    k_adjusted = k.transpose(-1,-2)\n",
        "\n",
        "    product = torch.matmul(q,k_adjusted)\n",
        "\n",
        "    if mask is not None:\n",
        "      product = product.masked_fill(mask==0,float(\"-1e20\"))\n",
        "\n",
        "    product = product/math.sqrt(self.single_head_dim)\n",
        "    scores = F.softmax(product,dim=-1)\n",
        "    scores = torch.matmul(scores,v)\n",
        "    concat = scores.transpose(1,2).contiguous().view(batch_size,seq_query_len,self.single_head_dim*self.n_heads)\n",
        "    output = self.output(concat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "5RhKDhMh2SfL"
      },
      "outputs": [],
      "source": [
        "class FeedForwardNetwork(nn.Module):\n",
        "  def __init__(self,embed_dim,expansion_factor=4):\n",
        "    super(FeedForwardNetwork,self).__init__()\n",
        "    self.fc1 = nn.Linear(embed_dim,expansion_factor*embed_dim)\n",
        "    self.fc2 = nn.Linear(expansion_factor*embed_dim,embed_dim)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "aWehs-lFjxcn"
      },
      "outputs": [],
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "  def __init__(self,embed_dim,n_heads=8,expansion_factor=4):\n",
        "    super(EncoderBlock,self).__init__()\n",
        "    self.attention = MultiHeadAttention(embed_dim,n_heads)\n",
        "    self.feed_forward = FeedForwardNetwork(embed_dim,expansion_factor*embed_dim)\n",
        "    self.norm_1 = nn.LayerNorm(embed_dim)\n",
        "    self.norm_2 = nn.LayerNorm(embed_dim)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "  def forward(self,x,mask):\n",
        "    attention_output = self.attention(x,x,x,mask)\n",
        "    x = self.norm_1(x + self.dropout(attention_output))\n",
        "    ff_output = self.feed_forward(x)\n",
        "    x = self.norm_2(x + self.dropout(ff_output))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "nD9GUGAC5w5i"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self,embed_dim,n_heads=8,expansion_factor=4):\n",
        "    super(DecoderBlock,self).__init__()\n",
        "    self.masked_attention = MultiHeadAttention(embed_dim,n_heads)\n",
        "    self.norm1 = nn.LayerNorm(embed_dim)\n",
        "    self.attention = MultiHeadAttention(embed_dim,n_heads)\n",
        "    self.norm2 = nn.LayerNorm(embed_dim)\n",
        "    self.feed_forward = FeedForwardNetwork(embed_dim,expansion_factor*embed_dim)\n",
        "    self.norm3 = nn.LayerNorm(embed_dim)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "  def forward(self,x,encoder_output,source_mask,target_mask):\n",
        "    masked_output = self.masked_output(x,x,x,target_mask)\n",
        "    x = self.norm1(x + self.dropout(masked_output))\n",
        "    attention_output = self.attention(encoder_output,encoder_output,x,source_mask)\n",
        "    x = self.norm2(x + self.dropout(attention_output))\n",
        "    ff_output = self.feed_forward(x)\n",
        "    x = self.norm3(x + self.dropout(ff_output))\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "TaqPZ1vMBkHI"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self,input_vocab_size,output_vocab_size,embed_dim=512,n_heads=8,expansion_factor=4,max_sentence_len=50,num_layers=2):\n",
        "    super(Transformer,self).__init__()\n",
        "    self.max_len = max_sentence_len\n",
        "    # self.tokenizer_en = en_tokenizer\n",
        "    # self.tokenizer_fr = fr_tokenizer\n",
        "    self.input_embedding = nn.Embedding(input_vocab_size,embed_dim)\n",
        "    self.positional_encoding = PositionalEmbedding(max_sentence_len,embed_dim)\n",
        "    self.output_embedding = nn.Embedding(output_vocab_size,embed_dim)\n",
        "    self.encoder_layer = nn.ModuleList([EncoderBlock(embed_dim,n_heads,expansion_factor)])\n",
        "    self.decoder_layer = nn.ModuleList([DecoderBlock(embed_dim,n_heads,expansion_factor)])\n",
        "    self.fc = nn.Linear(embed_dim,output_vocab_size)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "  def generate_mask(self,source,target):\n",
        "    source_mask = (source!=0).unsqueeze(1).unsqueeze(2)\n",
        "    target_mask = (target!=0).unsqueeze(2).unsqueeze(3)\n",
        "    seq_length = target.size(1)\n",
        "    nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
        "    target_mask = target_mask&nopeak_mask\n",
        "    return source_mask,target_mask\n",
        "  def forward(self,source,target):\n",
        "    source_mask,target_mask = self.generate_mask(source,target)\n",
        "    # source_ids = [en_vocab[token] for token in self.tokenizer_en(source)]\n",
        "    # source_padded_ids = F.pad(source_ids,pad=(0, self.max_len - len(source_ids)),mode = 'constant',value = en_vocab['<pad>'])\n",
        "    # source_padded_ids = torch.tensor(source_padded_ids,dtype = torch.long)\n",
        "    # print(type(source_padded_ids))\n",
        "    ip_embed = self.input_embedding(source)\n",
        "    ip_positional_encoding = self.positional_encoding(ip_embed)\n",
        "    ip_embedded = self.dropout(ip_positional_encoding)\n",
        "    encoder_output = ip_embedded\n",
        "    for enc_layer in self.encoder_layer:\n",
        "      encoder_output = enc_layer(encoder_output,source_mask)\n",
        "    # target_ids = [fr_vocab[token] for token in self.tokenizer_fr(target)]\n",
        "    # target_padded_ids = F.pad(target_ids,pad=(0, self.max_len - len(target_ids)),mode = 'constant',value = en_vocab['<pad>'])\n",
        "    # target_padded_ids = torch.tensor(target_padded_ids,dtype = torch.long)\n",
        "    # print(type(target_padded_ids))\n",
        "    op_embed = self.output_embedding(target)\n",
        "    op_positional_encoding = self.positional_encoding(op_embed)\n",
        "    op_embedded = self.dropout(op_positional_encoding)\n",
        "    for dec_layer in self.decoder_layer:\n",
        "      decoder_output = dec_layer(decoder_output,source_mask,target_mask)\n",
        "    output = self.fc(decoder_output)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "-ic4FGYKjjR_"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "lhu06ACEkehL"
      },
      "outputs": [],
      "source": [
        "def train(model,data_iterator,optimizer,criterion,clip):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_total = 0\n",
        "  epoch_corrects = 0\n",
        "\n",
        "  for _,(source,target) in enumerate(data_iterator):\n",
        "    print(source)\n",
        "    print(type(source))\n",
        "    source,target = source.to(device),target.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(source,target)\n",
        "    output = output[1:].view(-1,output.shape[-1])\n",
        "    target = target[1:].view(-1)\n",
        "\n",
        "    loss = criterion(output,target)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    corrects = torch.sum(predicted == target).item()\n",
        "    total = target.size(0)\n",
        "    accuracy = corrects / total\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss+=loss.item()\n",
        "    epoch_corrects+=corrects\n",
        "    epoch_total+=total\n",
        "  return epoch_loss/len(data_iterator),epoch_corrects/epoch_total\n",
        "\n",
        "def evaluate(model,data_iterator,criterion):\n",
        "\n",
        "  model.evaluate()\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_total = 0\n",
        "  epoch_corrects = 0\n",
        "\n",
        "  for _,(source,target) in enumerate(data_iterator):\n",
        "    source,target = source.to(device),target.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(source,target)\n",
        "    output = output[1:].view(-1,output.shape[-1])\n",
        "    target = target[1:].view(-1)\n",
        "\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    corrects = torch.sum(predicted == target).item()\n",
        "    total = target.size(0)\n",
        "    accuracy = corrects / total\n",
        "    loss = criterion(output,target)\n",
        "\n",
        "    epoch_loss+=loss.item()\n",
        "    epoch_corrects+=corrects\n",
        "    epoch_total+=total\n",
        "  return epoch_loss/len(data_iterator),epoch_corrects/epoch_total\n",
        "def epoch_time(start_time: int,\n",
        "               end_time: int):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ag0fiPFonjeU",
        "outputId": "8d1ca665-bd61-4c11-dda0-e1bd8d8d86f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11137412"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "source_vocab_size = len(en_vocab)+5\n",
        "target_vocab_size = len(fr_vocab)+5\n",
        "embed_dim = 512\n",
        "n_heads = 8\n",
        "num_layers = 6\n",
        "expansion_factor = 4\n",
        "max_sentence_length = 50\n",
        "transformer_model = Transformer(embed_dim,n_heads,expansion_factor,source_vocab_size,target_vocab_size,max_sentence_length,num_layers)\n",
        "count_parameters(transformer_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "N_EPOCHS = 5\n",
        "CLIP = 1\n",
        "loss_f = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "optimizer = optim.Adam(transformer_model.parameters(),lr = 0.0001,betas = (0.9,0.98),eps = 1e-9)\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "  start_time = time.time()\n",
        "  train_loss,train_accuracy = train(transformer_model,train_data_token_iter,optimizer,loss_f,CLIP)\n",
        "  val_loss,val_accuracy = evaluate(transformer_model,valid_data_token_iter,loss_f)\n",
        "  end_time = time.time()\n",
        "  epoch_min,epoch_sec = epoch_time(start_time,end_time)\n",
        "\n",
        "  print(f\"Epoch {epoch+1:02} completed | Time : {epoch_min}m and {epoch_sec}s\")\n",
        "  print(f\"\\tTrain Accuracy : {train_accuracy} | Train Loss : {train_loss}\")\n",
        "  print(f\"\\tVal Accuracy : {val_accuracy} | Val Loss : {val_loss}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
